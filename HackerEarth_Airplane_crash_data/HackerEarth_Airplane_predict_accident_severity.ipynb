{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "      <th>Safety_Score</th>\n",
       "      <th>Days_Since_Inspection</th>\n",
       "      <th>Total_Safety_Complaints</th>\n",
       "      <th>Control_Metric</th>\n",
       "      <th>Turbulence_In_gforces</th>\n",
       "      <th>Cabin_Temperature</th>\n",
       "      <th>Accident_Type_Code</th>\n",
       "      <th>Max_Elevation</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Adverse_Weather_Metric</th>\n",
       "      <th>Accident_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>49.223744</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>71.285324</td>\n",
       "      <td>0.272118</td>\n",
       "      <td>78.04</td>\n",
       "      <td>2</td>\n",
       "      <td>31335.476824</td>\n",
       "      <td>3</td>\n",
       "      <td>0.424352</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>62.465753</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>72.288058</td>\n",
       "      <td>0.423939</td>\n",
       "      <td>84.54</td>\n",
       "      <td>2</td>\n",
       "      <td>26024.711057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>12128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Significant_Damage_And_Fatalities</td>\n",
       "      <td>63.059361</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>66.362808</td>\n",
       "      <td>0.322604</td>\n",
       "      <td>78.86</td>\n",
       "      <td>7</td>\n",
       "      <td>39269.053927</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
       "      <td>48.082192</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>74.703737</td>\n",
       "      <td>0.337029</td>\n",
       "      <td>81.79</td>\n",
       "      <td>3</td>\n",
       "      <td>42771.499200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211728</td>\n",
       "      <td>5946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Significant_Damage_And_Fatalities</td>\n",
       "      <td>26.484018</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>47.948952</td>\n",
       "      <td>0.541140</td>\n",
       "      <td>77.16</td>\n",
       "      <td>3</td>\n",
       "      <td>35509.228515</td>\n",
       "      <td>2</td>\n",
       "      <td>0.176883</td>\n",
       "      <td>9054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Severity  Safety_Score  \\\n",
       "0                Minor_Damage_And_Injuries     49.223744   \n",
       "1                Minor_Damage_And_Injuries     62.465753   \n",
       "2        Significant_Damage_And_Fatalities     63.059361   \n",
       "3  Significant_Damage_And_Serious_Injuries     48.082192   \n",
       "4        Significant_Damage_And_Fatalities     26.484018   \n",
       "\n",
       "   Days_Since_Inspection  Total_Safety_Complaints  Control_Metric  \\\n",
       "0                     14                       22       71.285324   \n",
       "1                     10                       27       72.288058   \n",
       "2                     13                       16       66.362808   \n",
       "3                     11                        9       74.703737   \n",
       "4                     13                       25       47.948952   \n",
       "\n",
       "   Turbulence_In_gforces  Cabin_Temperature  Accident_Type_Code  \\\n",
       "0               0.272118              78.04                   2   \n",
       "1               0.423939              84.54                   2   \n",
       "2               0.322604              78.86                   7   \n",
       "3               0.337029              81.79                   3   \n",
       "4               0.541140              77.16                   3   \n",
       "\n",
       "   Max_Elevation  Violations  Adverse_Weather_Metric  Accident_ID  \n",
       "0   31335.476824           3                0.424352         7570  \n",
       "1   26024.711057           2                0.352350        12128  \n",
       "2   39269.053927           3                0.003364         2181  \n",
       "3   42771.499200           1                0.211728         5946  \n",
       "4   35509.228515           2                0.176883         9054  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Highly_Fatal_And_Damaging                  3049\n",
       "Significant_Damage_And_Serious_Injuries    2729\n",
       "Minor_Damage_And_Injuries                  2527\n",
       "Significant_Damage_And_Fatalities          1695\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sev={\n",
    "'Minor_Damage_And_Injuries':'0',\n",
    "'Highly_Fatal_And_Damaging':'1',\n",
    "'Significant_Damage_And_Serious_Injuries':'2',\n",
    "'Significant_Damage_And_Fatalities':'3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sev']=df['Severity'].map(dict_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      "Severity                   10000 non-null object\n",
      "Safety_Score               10000 non-null float64\n",
      "Days_Since_Inspection      10000 non-null int64\n",
      "Total_Safety_Complaints    10000 non-null int64\n",
      "Control_Metric             10000 non-null float64\n",
      "Turbulence_In_gforces      10000 non-null float64\n",
      "Cabin_Temperature          10000 non-null float64\n",
      "Accident_Type_Code         10000 non-null int64\n",
      "Max_Elevation              10000 non-null float64\n",
      "Violations                 10000 non-null int64\n",
      "Adverse_Weather_Metric     10000 non-null float64\n",
      "Accident_ID                10000 non-null int64\n",
      "sev                        10000 non-null object\n",
      "dtypes: float64(6), int64(5), object(2)\n",
      "memory usage: 1015.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Severity                   0\n",
       "Safety_Score               0\n",
       "Days_Since_Inspection      0\n",
       "Total_Safety_Complaints    0\n",
       "Control_Metric             0\n",
       "Turbulence_In_gforces      0\n",
       "Cabin_Temperature          0\n",
       "Accident_Type_Code         0\n",
       "Max_Elevation              0\n",
       "Violations                 0\n",
       "Adverse_Weather_Metric     0\n",
       "Accident_ID                0\n",
       "sev                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('Severity',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "      <th>Safety_Score</th>\n",
       "      <th>Days_Since_Inspection</th>\n",
       "      <th>Total_Safety_Complaints</th>\n",
       "      <th>Control_Metric</th>\n",
       "      <th>Turbulence_In_gforces</th>\n",
       "      <th>Cabin_Temperature</th>\n",
       "      <th>Accident_Type_Code</th>\n",
       "      <th>Max_Elevation</th>\n",
       "      <th>Violations</th>\n",
       "      <th>Adverse_Weather_Metric</th>\n",
       "      <th>Accident_ID</th>\n",
       "      <th>sev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>49.223744</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>71.285324</td>\n",
       "      <td>0.272118</td>\n",
       "      <td>78.04</td>\n",
       "      <td>2</td>\n",
       "      <td>31335.476824</td>\n",
       "      <td>3</td>\n",
       "      <td>0.424352</td>\n",
       "      <td>7570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Minor_Damage_And_Injuries</td>\n",
       "      <td>62.465753</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>72.288058</td>\n",
       "      <td>0.423939</td>\n",
       "      <td>84.54</td>\n",
       "      <td>2</td>\n",
       "      <td>26024.711057</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>12128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Severity  Safety_Score  Days_Since_Inspection  \\\n",
       "0  Minor_Damage_And_Injuries     49.223744                     14   \n",
       "1  Minor_Damage_And_Injuries     62.465753                     10   \n",
       "\n",
       "   Total_Safety_Complaints  Control_Metric  Turbulence_In_gforces  \\\n",
       "0                       22       71.285324               0.272118   \n",
       "1                       27       72.288058               0.423939   \n",
       "\n",
       "   Cabin_Temperature  Accident_Type_Code  Max_Elevation  Violations  \\\n",
       "0              78.04                   2   31335.476824           3   \n",
       "1              84.54                   2   26024.711057           2   \n",
       "\n",
       "   Adverse_Weather_Metric  Accident_ID sev  \n",
       "0                0.424352         7570   0  \n",
       "1                0.352350        12128   0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['sev','Severity'],axis=1)\n",
    "y=df['sev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akashmas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\akashmas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(lr_pred))\n",
    "print(type(y_test))\n",
    "# earlier lr_pred was numpy arr. converted to pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred=pd.Series(lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       963\n",
      "           1       0.81      0.57      0.67      1411\n",
      "           2       0.41      0.60      0.48       633\n",
      "           3       0.16      0.29      0.20       293\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      3300\n",
      "   macro avg       0.51      0.50      0.49      3300\n",
      "weighted avg       0.63      0.55      0.57      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akashmas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       923\n",
      "           1       0.88      0.88      0.88      1001\n",
      "           2       0.83      0.88      0.85       877\n",
      "           3       0.82      0.89      0.86       499\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3300\n",
      "   macro avg       0.85      0.86      0.85      3300\n",
      "weighted avg       0.85      0.85      0.85      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rfc_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmclf=svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akashmas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.30      0.47      3300\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.30      0.30      0.30      3300\n",
      "   macro avg       0.25      0.08      0.12      3300\n",
      "weighted avg       1.00      0.30      0.47      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akashmas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svmclf.fit(X_train,y_train)\n",
    "svmclf_pred=svmclf.predict(X_test)\n",
    "print(classification_report(svmclf_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.24      0.28      1122\n",
      "           1       0.36      0.31      0.34      1149\n",
      "           2       0.23      0.29      0.26       736\n",
      "           3       0.08      0.14      0.10       293\n",
      "\n",
      "   micro avg       0.27      0.27      0.27      3300\n",
      "   macro avg       0.25      0.25      0.24      3300\n",
      "weighted avg       0.29      0.27      0.28      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn_pred=knn.predict(X_test)\n",
    "print(classification_report(knn_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50       791\n",
      "           1       0.57      0.50      0.53      1148\n",
      "           2       0.50      0.44      0.47      1075\n",
      "           3       0.24      0.45      0.31       286\n",
      "\n",
      "   micro avg       0.47      0.47      0.47      3300\n",
      "   macro avg       0.45      0.47      0.45      3300\n",
      "weighted avg       0.50      0.47      0.48      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(X_train, y_train) \n",
    "gnb_pred = gnb.predict(X_test) \n",
    "print(classification_report(gnb_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78       972\n",
      "           1       0.80      0.91      0.85       882\n",
      "           2       0.86      0.87      0.86       919\n",
      "           3       0.83      0.85      0.84       527\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      3300\n",
      "   macro avg       0.83      0.84      0.83      3300\n",
      "weighted avg       0.83      0.83      0.83      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(X_train, y_train) \n",
    "xgb_pred = xgb.predict(X_test) \n",
    "print(classification_report(xgb_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's multi_logloss: 1.30794\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.25243\n",
      "[3]\tvalid_0's multi_logloss: 1.20889\n",
      "[4]\tvalid_0's multi_logloss: 1.16015\n",
      "[5]\tvalid_0's multi_logloss: 1.11757\n",
      "[6]\tvalid_0's multi_logloss: 1.07439\n",
      "[7]\tvalid_0's multi_logloss: 1.04321\n",
      "[8]\tvalid_0's multi_logloss: 1.00722\n",
      "[9]\tvalid_0's multi_logloss: 0.981687\n",
      "[10]\tvalid_0's multi_logloss: 0.959349\n",
      "[11]\tvalid_0's multi_logloss: 0.928504\n",
      "[12]\tvalid_0's multi_logloss: 0.900009\n",
      "[13]\tvalid_0's multi_logloss: 0.876981\n",
      "[14]\tvalid_0's multi_logloss: 0.851162\n",
      "[15]\tvalid_0's multi_logloss: 0.829327\n",
      "[16]\tvalid_0's multi_logloss: 0.803295\n",
      "[17]\tvalid_0's multi_logloss: 0.779693\n",
      "[18]\tvalid_0's multi_logloss: 0.759496\n",
      "[19]\tvalid_0's multi_logloss: 0.738332\n",
      "[20]\tvalid_0's multi_logloss: 0.723742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's multi_logloss: 0.723742\n",
      "Starting predicting...\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "\n",
    "#X_train.drop('Severity',axis=1,inplace=True)\n",
    "#X_train['sev']=X_train['sev'].astype('int64')\n",
    "\n",
    "#y_train = df_train[0]\n",
    "#y_test = df_test[0]\n",
    "#X_train = df_train.drop(0, axis=1)\n",
    "#X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',  # or regression\n",
    "    'num_class':4,   # for multiclass\n",
    "    #'metric': {'l2', 'l1'},   # for regression\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "#print('Saving model...')\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "\n",
    "gbm_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test))\n",
    "print(type(y_train))\n",
    "print(type(X_train))\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.info()\n",
    "#X_test.info()\n",
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.astype('int64')\n",
    "y_train=y_train.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-7c5694f4fdf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     \"\"\"\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(gbm_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39190619, 0.21159327, 0.27794084, 0.11855969],\n",
       "       [0.22982688, 0.13287524, 0.1416292 , 0.49566868],\n",
       "       [0.13104147, 0.21152215, 0.131676  , 0.52576038],\n",
       "       ...,\n",
       "       [0.15819164, 0.20725787, 0.53133446, 0.10321603],\n",
       "       [0.31454134, 0.2842324 , 0.25166655, 0.1495597 ],\n",
       "       [0.13613257, 0.63115365, 0.14523374, 0.08748004]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-1c9011af8085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The rmse of prediction is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbm_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 239\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 87\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=4)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, gbm_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       842\n",
      "           1       0.91      0.91      0.91       997\n",
      "           2       0.92      0.91      0.91       940\n",
      "           3       0.87      0.90      0.88       521\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      3300\n",
      "   macro avg       0.90      0.90      0.90      3300\n",
      "weighted avg       0.90      0.90      0.90      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dfc=DecisionTreeClassifier()\n",
    "dfc.fit(X_train, y_train) \n",
    "dfc_pred = dfc.predict(X_test) \n",
    "print(classification_report(dfc_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so Decision Tree Classifier has worked well over others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a8692905334109ab81a408b317bb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15.25 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.9000000000000001, min_samples_leaf=3, min_samples_split=2, n_estimators=100)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(verbosity=2, max_time_mins=15)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                            criterion='friedman_mse', init=None,\n",
       "                                            learning_rate=0.5, loss='deviance',\n",
       "                                            max_depth=10,\n",
       "                                            max_features=0.9000000000000001,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=15,\n",
       "                                            min_samples_split=7,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=100,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='deprecated',\n",
       "                                            random_state=None, subsample=0.45,\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tpot.export('tpot_airplane_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
